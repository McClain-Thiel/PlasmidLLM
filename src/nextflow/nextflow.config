/*
 * SPACE Pipeline Configuration
 * Scalable Plasmid Annotation & Classification Engine
 */

params {
    // Input/Output
    input_pattern   = "${projectDir}/../../tests/data/*.{gb,gbk,fasta,fa,json}"
    outdir          = "results"

    // AWS S3 data locations
    s3_bucket       = "s3://phd-research-storage-1758274488"
    s3_raw_data     = "${s3_bucket}/plasmid_data_20251209/0_raw"
    s3_output       = "${s3_bucket}/plasmid_data_20251209/pipeline_output"

    // Database paths (override these for HPC)
    bakta_db        = "${projectDir}/databases/bakta"
    copla_db        = "${projectDir}/databases/copla"

    // Processing options
    threads         = 4
    skip_bakta      = false
    skip_mobsuite   = false
    skip_copla      = false
    skip_qc         = false

    // HPC-specific options
    scratch_dir     = null  // Set to your Scratch directory on HPC
    queue           = null  // SGE queue name (e.g., 'short.qc' on Myriad)
    max_memory      = '64.GB'
    max_cpus        = 36
    max_time        = '72.h'

    // Use conda instead of containers for Python processes (for HPC)
    use_conda       = false
}

profiles {
    standard {
        process.executor = 'local'
    }

    docker {
        docker.enabled = true
        docker.runOptions = '-u $(id -u):$(id -g)'
    }

    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
    }

    local {
        // For running with locally installed tools
        process.executor = 'local'
    }

    test {
        params.input_pattern = "${projectDir}/../../tests/data/*.gbk"
        params.outdir = "test_results"
    }

    // UCL Myriad cluster (SGE scheduler)
    // Based on nf-core ucl_myriad config: https://nf-co.re/configs/ucl_myriad/
    myriad {
        params.use_conda = true
        params.bakta_db = System.getenv('HOME') + '/Scratch/databases/bakta'

        process.executor = 'sge'
        process.penv = 'smp'  // Parallel environment for multi-threaded jobs

        // nf-core recommends: memory per cpu, max 100 jobs, 10/sec submit rate
        executor.queueSize = 100
        executor.submitRateLimit = '10 sec'

        // Memory is per-CPU on Myriad, so divide by cpus
        process.clusterOptions = { "-l h_rt=${task.time?.toSeconds() ?: 3600},h_vmem=${(task.memory?.toGiga() ?: 4).intdiv(task.cpus ?: 1)}G,mem_free=${(task.memory?.toGiga() ?: 4).intdiv(task.cpus ?: 1)}G" }

        // Apptainer/Singularity configuration for external tools
        apptainer.enabled = true
        apptainer.autoMounts = true
        apptainer.cacheDir = System.getenv('HOME') + '/Scratch/.apptainer/cache'
        apptainer.pullTimeout = '60 min'

        // Bind the database directory and scratch
        apptainer.runOptions = "-B ${System.getenv('HOME')}/Scratch:${System.getenv('HOME')}/Scratch"

        // Module to load before running (conda for Python, apptainer for bio tools)
        process.beforeScript = 'source /etc/profile.d/modules.sh && source /shared/ucl/apps/miniconda/24.3.0-0/etc/profile.d/conda.sh && conda activate space && module load apptainer && export APPTAINER_TMPDIR=$HOME/Scratch/.apptainer/tmp && export APPTAINER_CACHEDIR=$HOME/Scratch/.apptainer/cache'

        // Default queue
        process.queue = params.queue ?: null
    }

    // Myriad with AWS S3 data
    myriad_s3 {
        params.use_conda = true
        params.bakta_db = System.getenv('HOME') + '/Scratch/databases/bakta'
        params.input_pattern = "${params.s3_raw_data}/GenBank/GenBank/gbk/*.gbk"
        params.outdir = "${params.s3_output}"

        // Include all myriad settings
        process.executor = 'sge'
        process.penv = 'smp'
        executor.queueSize = 100
        executor.submitRateLimit = '10 sec'
        process.clusterOptions = { "-l h_rt=${task.time?.toSeconds() ?: 3600},h_vmem=${(task.memory?.toGiga() ?: 4).intdiv(task.cpus ?: 1)}G,mem_free=${(task.memory?.toGiga() ?: 4).intdiv(task.cpus ?: 1)}G" }

        apptainer.enabled = true
        apptainer.autoMounts = true
        apptainer.cacheDir = System.getenv('HOME') + '/Scratch/.apptainer/cache'
        apptainer.pullTimeout = '60 min'
        apptainer.runOptions = "-B ${System.getenv('HOME')}/Scratch:${System.getenv('HOME')}/Scratch"

        process.beforeScript = 'source /etc/profile.d/modules.sh && source /shared/ucl/apps/miniconda/24.3.0-0/etc/profile.d/conda.sh && conda activate space && module load apptainer && export APPTAINER_TMPDIR=$HOME/Scratch/.apptainer/tmp && export APPTAINER_CACHEDIR=$HOME/Scratch/.apptainer/cache'

        // AWS credentials from environment
        aws.region = 'us-east-1'
        aws.batch.cliPath = '/usr/local/bin/aws'
    }

    // UCL Kathleen cluster (SGE - old system)
    kathleen {
        process.executor = 'sge'
        process.penv = 'mpi'  // Kathleen is MPI-focused

        apptainer.enabled = true
        apptainer.autoMounts = true
        apptainer.cacheDir = "${params.scratch_dir ?: System.getenv('HOME') + '/Scratch'}/.apptainer/cache"
        apptainer.runOptions = { "-B ${params.bakta_db}:${params.bakta_db}" }

        process.beforeScript = 'module load apptainer'
    }

    // UCL Kathleen-NG cluster (SLURM - new system)
    kathleen_slurm {
        process.executor = 'slurm'

        apptainer.enabled = true
        apptainer.autoMounts = true
        apptainer.cacheDir = "${params.scratch_dir ?: System.getenv('HOME') + '/Scratch'}/.apptainer/cache"
        apptainer.runOptions = { "-B ${params.bakta_db}:${params.bakta_db}" }

        process.beforeScript = 'module load apptainer'

        // SLURM resource requests
        process.clusterOptions = { "--mem=${task.memory?.toMega() ?: 4000}M" }
    }
}

// Process-specific containers and resources
process {
    // Default for Python scripts - use container only if not using conda
    withLabel: 'python' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '2 GB'
    }

    // Normalization
    withName: 'NORMALIZE' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '2 GB'
    }

    // Track 1: Engineered scan (PlasmidKit)
    withName: 'SCAN_ENGINEERED' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '2 GB'
    }

    // Track 2: Natural scan - always use containers for these
    withName: 'RUN_BAKTA' {
        container = 'docker://oschwengers/bakta:latest'
        cpus = { params.threads }
        memory = '8 GB'
        time = '4.h'
    }

    withName: 'RUN_MOBSUITE' {
        container = 'docker://kbessonov/mob_suite:3.0.3'
        cpus = { params.threads }
        memory = '4 GB'
        time = '1.h'
    }

    withName: 'RUN_COPLA' {
        container = 'docker://rpalcab/copla:1.0'
        cpus = 2
        memory = '4 GB'
        time = '1.h'
    }

    withName: 'PARSE_NATURAL' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '2 GB'
    }

    // Track 3: QC
    withName: 'SEQ_QC' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '1 GB'
    }

    // Classifier
    withName: 'CLASSIFY' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '1 GB'
    }

    // Export
    withName: 'EXPORT_PARQUET' {
        container = { params.use_conda ? null : 'space-pipeline:latest' }
        cpus = 1
        memory = '4 GB'
    }

    // Database setup
    withName: 'DOWNLOAD_BAKTA_DB' {
        container = 'docker://oschwengers/bakta:latest'
        cpus = 1
        memory = '4 GB'
    }
}

// Seqera Platform (Tower) Integration
// Set your access token below or via TOWER_ACCESS_TOKEN environment variable
tower {
    enabled = true
    accessToken = System.getenv('TOWER_ACCESS_TOKEN') ?: 'eyJ0aWQiOiAxMzI2Nn0uZmU3ZWE0ZDZlNmJlZjJiNTE0NmI1MmM2YzgxMmY1MWIzZGM5Yzg2ZQ=='
    workspaceId = System.getenv('TOWER_WORKSPACE_ID') ?: null
}

// Manifest
manifest {
    name            = 'SPACE'
    author          = 'Plasmid Pretraining Project'
    description     = 'Scalable Plasmid Annotation & Classification Engine'
    version         = '0.1.0'
    nextflowVersion = '>=23.04.0'
    mainScript      = 'main.nf'
}

// Execution reports
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/timeline.html"
    overwrite = true
}

report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/report.html"
    overwrite = true
}

trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/trace.txt"
    overwrite = true
}

dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/dag.svg"
    overwrite = true
}
